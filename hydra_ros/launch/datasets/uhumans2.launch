<launch>
    <arg name="sim_time_required" default="true"/>
    <param name="use_sim_time" value="$(arg sim_time_required)"/>

    <arg name="use_gt_semantics" default="true" doc="use simulator-provider semantics"/>
    <arg name="color_mesh_by_label" default="false" doc="display mesh colored by semantic label"/>
    <arg name="use_single_channel_label_image" default="false"/>

    <arg name="robot_frame" default="base_link_gt" doc="robot body tf frame"/>
    <arg name="hydra_config_path" default="$(find hydra)/config/datasets/uhumans2.yaml"/>
    <!-- lcd config -->
    <arg name="use_gnn_descriptors" default="false"/>
    <arg name="lcd_config_name" default="$(eval 'uhumans2_gnn.yaml' if use_gnn_descriptors else 'uhumans2.yaml')"/>
    <arg name="lcd_config_path" default="$(find hydra)/config/lcd/$(arg lcd_config_name)"/>

    <!-- semantics -->
    <arg name="labelspace_name" default="$(eval 'uhumans2_office' if use_gt_semantics else 'ade20k_mp3d')" doc="semantic label space"/>
    <arg name="semantic_map_path" default="$(find hydra_ros)/config/color/$(arg labelspace_name).csv" if="$(arg use_gt_semantics)"/>
    <arg name="semantic_label_remap_filepath" default="$(find hydra)/config/label_remaps/uhumans2_office.yaml" if="$(arg use_single_channel_label_image)"/>

    <arg name="use_prerecorded_semantics" default="false" doc="Use precorded labels as input"/>
    <arg name="prerecorded_topic" default="/oneformer/labels/image_raw" doc="Topic containing prerecorded labels"/>

    <arg name="use_gt_frame" value="$(eval robot_frame == 'base_link_gt')"/>
    <arg name="rgb_topic" default="/tesse/left_cam/rgb/image_raw"/>
    <arg name="rgb_info_topic" default="/tesse/left_cam/camera_info"/>
    <arg name="depth_topic" default="/tesse/depth_cam/mono/image_raw"/>
    <arg name="label_topic" default="semantic_inference/semantic/image_raw" unless="$(arg use_gt_semantics)"/>
    <arg name="label_topic" default="$(eval '/tesse/seg_cam/converted/image_raw' if use_single_channel_label_image else '/tesse/seg_cam/rgb/image_raw')"
                            if="$(arg use_gt_semantics)"/>

    <arg name="use_static_tfs" default="true" doc="publish static tfs from file"/>
    <group if="$(arg use_static_tfs)">
        <include file="$(find hydra_ros)/launch/static_tfs/uhumans2_static_tfs.xml"/>
        <node pkg="tf2_ros" type="static_transform_publisher" name="world_map_bridge_tf" args="0 0 0 0 0 0 1 world map" if="$(arg use_gt_frame)"/>
        <node pkg="tf2_ros" type="static_transform_publisher" name="map_odom_bridge_tf" args="0 0 0 0 0 0 1 map odom" if="$(arg use_gt_frame)"/>
    </group>

    <group if="$(eval robot_frame == 'base_link_noisy')">
        <arg name="start_gt_lcd" default="true"/>
        <remap from="noisy_tf_publisher_node/gt_odom_in" to="tesse/odom"/>
        <remap from="vlc_server_node/camera_info" to="tesse/left_cam/camera_info"/>
        <remap from="vlc_server_node/image_in" to="tesse/left_cam/rgb/image_raw"/>
        <remap from="vlc_server_node/depth_in" to="tesse/depth_cam/mono/image_raw"/>
        <remap from="vlc_server_node/loop_closure_output" to="hydra_ros_node/external_loop_closures"/>
        <node pkg="tf2_ros" type="static_transform_publisher" name="map_odom_bridge_tf" args="0 0 0 0 0 0 1 map odom"/>
        <include file="$(find hydra_ros)/launch/utils/noisy_odometry.launch">
            <arg name="parent_frame" value="odom"/>
            <arg name="child_frame" value="base_link_noisy"/>
            <arg name="gt_parent_frame" value="world"/>
            <arg name="gt_child_frame" value="base_link_gt"/>
            <arg name="start_gt_lcd" value="$(arg start_gt_lcd)"/>
        </include>
    </group>

    <group unless="$(arg use_gt_semantics)">
        <remap from="semantic_inference/color/image_raw" to="$(arg rgb_topic)"/>
        <remap from="semantic_inference/labels/image_raw" to="$(arg prerecorded_topic)" if="$(arg use_prerecorded_semantics)"/>
        <include file="$(find semantic_inference_ros)/launch/semantic_inference.launch" pass_all_args="true"/>
    </group>

    <arg name="use_openset_features" default="false" doc="assign clip features to places"/>
    <group if="$(arg use_openset_features)">
        <remap from="/clip_publisher_node/image" to="/tesse/left_cam/rgb/image_raw"/>
        <remap from="/clip_publisher_node/feature" to="/hydra_ros_node/input/left_cam/feature"/>
        <include file="$(find semantic_inference_ros)/launch/clip_publisher.launch"/>
    </group>

    <remap from="hydra_ros_node/input/left_cam/depth_registered/image_rect" to="$(arg depth_topic)"/>
    <remap from="hydra_ros_node/input/left_cam/rgb/image_raw" to="$(arg rgb_topic)"/>
    <remap from="hydra_ros_node/input/left_cam/rgb/camera_info" to="$(arg rgb_info_topic)"/>
    <remap from="hydra_ros_node/input/left_cam/semantic/image_raw" to="$(arg label_topic)"/>
    <remap from="hydra_ros_node/pose_graph" to="kimera_vio_ros/pose_graph_incremental" unless="$(arg use_gt_frame)"/>
    <include file="$(find hydra_ros)/launch/hydra.launch" pass_all_args="true">
        <arg name="dataset_name" default="uhumans2"/>
        <arg name="rviz_path" default="$(find hydra_ros)/rviz/uhumans2.rviz"/>
    </include>
</launch>
